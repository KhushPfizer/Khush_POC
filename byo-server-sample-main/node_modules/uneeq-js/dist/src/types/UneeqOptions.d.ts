import { VoiceInputMode } from './VoiceInputMode';
export interface UneeqOptions {
    /** Server URL to connect to. */
    url: string;
    /** The API Key to access the Uneeq service. */
    apiKey?: string;
    /** The div element that the avatars video should be placed inside. */
    avatarVideoContainerElement: HTMLDivElement;
    /** The div element that the local video should be placed inside. */
    localVideoContainerElement: HTMLDivElement;
    /** Uneeq conversation ID to use for the session. */
    conversationId: string;
    /**
     * @ignore
     */
    customData?: any;
    /** Provide a function to be used for message handler call backs. */
    messageHandler?: (msg: any) => void;
    /** Whether you want to receive mic activity messages or not. Default value is false. */
    micActivityMessages?: boolean;
    /** Device ID of the preferred microphone to start the session with. */
    preferredMicrophoneId?: string;
    /** Device ID of the preferred camera to start the session with. */
    preferredCameraId?: string;
    /** Device ID of the preferred speaker to start the session with. */
    preferredSpeakerId?: string;
    /** Enable Logging. Default value is false. */
    logging?: boolean;
    /** Play Welcome Message. Default value is false. */
    playWelcome?: boolean;
    /** Enable diagnostic callbacks. Default value is false. */
    diagnostics?: boolean;
    /** Whether the users local video stream (camera) should be sent on session start. Default value is true. */
    sendLocalVideo?: boolean;
    /** Whether the users local audio stream (microphone) should be sent on session start. Default value is true. */
    sendLocalAudio?: boolean;
    /**
     * This option controls the visibility of client-side network performance messages in the developer console.
     * These WebRTC statistics (eg packetsLost, framesDropped, framesPerSec) help identify if session quality is being
     * impacted by client-side conditions.
     * Irrespective of this visibility setting, UneeQ's servers receive these messages to help measure platform
     * performance and stability for end users.
     */
    enableClientPerformanceMessage?: boolean;
    /**
     * This option controls whether the Digital Human is rendered with a transparent background,
     * allowing them to be overlaid on top of your experience.
     * If true, the digital human's configured background image will be replaced with a transparent background.
     * If false, your configured background image will be displayed. Defaults to false.
     */
    enableTransparentBackground?: boolean;
    /**
     * This option specifies what the default voice input mode will be.
     */
    voiceInputMode: VoiceInputMode | string;
    /**
     * This option specifies whether VAD should be used when voiceInputMode is set to SPEECH_RECOGNITION.
     * If set to false, then pauseSpeechRecognition and resumeSpeechRecognition must be called to capture the users audio.
     * If set to true, or omitted, then the users audio will be captured automatically.
     */
    enableVad?: boolean;
    /**
     * Resume user session if available.
     */
    resumeSession?: boolean;
    /**
     * This option specifies the URL of the background image to be used when the digital human is rendered.
     */
    backgroundImageUrl?: string;
    /**
     * This option specifies the URL of the name tag image to be used when the digital human is rendered.
     */
    nameTagImageUrl?: string;
    /**
     * This option specifies up to four locales that the Digital Human should understand a person speaking (speech recognition)
     * The locales are specified in the BCP-47 format e.g "en-US".
     * The first locale is considered the primary locale.
     * Locales should be separated with a colon e.g "en-US:en-GB:en-AU".
     */
    speechToTextLocales?: string;
    /**
     * Override the asset base path.
     */
    assetBasePath?: string;
    /**
     * Speech Recognition Hint Phrases
     * A comma separated list of phrases the speech recognition system should expect.
     */
    speechRecognitionHintPhrases?: string;
    /**
     * Speech Recognition Hint Phrases Boost
     * An integer number between 0 and 20 that can be used to boost the hint phrases likely hood to match.
     */
    speechRecognitionHintPhrasesBoost?: number;
    /**
     * Custom Metadata
     * A stringified value that will be sent to BYO NLPs with all chat calls like playWelcomeMessage and sendTranscript requests.
     * This can be set to any stringified value.
     */
    customMetadata?: string;
    /**
     * Enable Interrupt By Speech
     * When using SPEECH_RECOGNITION mode, this option will allow the user to interrupt the Digital Human by speaking over them.
     * If this value is false, the Digital Human will not be interrupted by the user. The default value is false - users cannot
     * interrupt the Digital Human. Note: Sending a text message will interrupt the digital human irrespective of this setting.
     */
    enableInterruptBySpeech?: boolean;
}
